{
  "description": "Optimized AI model parameters for each workflow stage",
  "version": "1.0.0",
  "updated": "2025-01-10",

  "stages": {
    "research": {
      "description": "Stage 1: Master SEO Research - Factual competitor analysis",
      "temperature": 0.3,
      "top_p": 0.9,
      "frequency_penalty": 0.2,
      "presence_penalty": 0.1,
      "max_tokens": 8000,
      "response_format": {
        "type": "json_object"
      }
    },

    "topics": {
      "description": "Stage 2: Topic Generation - Strategic topic selection with creativity",
      "temperature": 0.4,
      "top_p": 0.95,
      "frequency_penalty": 0.3,
      "presence_penalty": 0.2,
      "max_tokens": 16000,
      "response_format": {
        "type": "json_object"
      }
    },

    "deep_research": {
      "description": "Stage 3: Deep Topic Research - Detailed competitor analysis",
      "temperature": 0.3,
      "top_p": 0.9,
      "frequency_penalty": 0.1,
      "presence_penalty": 0.1,
      "max_tokens": 8000,
      "response_format": {
        "type": "json_object"
      }
    },

    "content": {
      "description": "Stage 4: Content Creation - High-quality article generation",
      "temperature": 0.6,
      "top_p": 0.92,
      "frequency_penalty": 0.3,
      "presence_penalty": 0.1,
      "max_tokens": 8000,
      "response_format": {
        "type": "json_object"
      }
    },

    "json_parser": {
      "description": "OpenAI GPT-4o JSON parsing (Stage 1 fallback)",
      "temperature": 0.1,
      "top_p": 0.9,
      "frequency_penalty": 0,
      "presence_penalty": 0,
      "max_tokens": 8000,
      "response_format": {
        "type": "json_object"
      }
    }
  },

  "model_priorities": {
    "research": ["groq/compound", "groq/compound-mini", "openai/gpt-oss-20b", "openai/gpt-oss-120b", "gemini-2.5-pro", "meta-llama/llama-4-maverick-17b-128e-instruct"],
    "topics": ["groq/compound", "groq/compound-mini", "openai/gpt-oss-20b", "openai/gpt-oss-120b", "gemini-2.5-pro", "meta-llama/llama-4-maverick-17b-128e-instruct"],
    "deep_research": ["groq/compound", "openai/gpt-oss-120b", "gpt-4o", "meta-llama/llama-4-maverick-17b-128e-instruct"],
    "content": ["groq/compound", "openai/gpt-oss-120b", "gpt-4o", "meta-llama/llama-4-maverick-17b-128e-instruct"]
  },

  "search_settings": {
    "groq_compound": {
      "country": "india",
      "include_domains": ["*.in", "groww.in", "zerodha.com", "etmoney.com", "paytmmoney.com", "indmoney.com"],
      "exclude_domains": ["wikipedia.org", "*.wiki*"]
    },
    "browser_search": {
      "tools": [{"type": "browser_search"}],
      "tool_choice": "auto"
    },
    "gemini_search": {
      "tools": [{"googleSearch": {}}]
    }
  },

  "parameter_explanations": {
    "temperature": "Controls randomness (0.0-1.0). Lower = more focused, higher = more creative",
    "top_p": "Nucleus sampling (0.0-1.0). Controls diversity of token selection",
    "frequency_penalty": "Reduces repetition of tokens (-2.0 to 2.0). Positive values discourage repeating tokens",
    "presence_penalty": "Encourages topic diversity (-2.0 to 2.0). Positive values encourage new topics",
    "max_tokens": "Maximum output length. Includes both prompt and completion",
    "response_format": "Forces structured JSON output (when supported by model)"
  },

  "tuning_notes": {
    "research": "Low temperature for factual accuracy. Moderate penalties to avoid repetitive gap analysis",
    "topics": "Balanced temperature for creative but consistent topics. Higher penalties to ensure 50 unique topics",
    "deep_research": "Low temperature for accurate competitor analysis. Minimal penalties to preserve detailed insights",
    "content": "Moderate temperature for engaging yet accurate content. Higher frequency_penalty to avoid repetitive phrasing"
  }
}
